# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eXoUZQ3oCxVWvlVuG-c7d5W9N7jqMUt3
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.ensemble import IsolationForest



train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

print("Train shape:", train.shape)
print("Test shape:", test.shape)


print("\n===== TRAIN HEAD =====")
print(train.head())

print("\n===== INFO =====")
print(train.info())

print("\n===== STATS =====")
print(train.describe())



print("\n===== Missing values =====")
print(train.isnull().sum())



num_cols = train.select_dtypes(include=np.number).columns
cat_cols = train.select_dtypes(exclude=np.number).columns

train[num_cols] = train[num_cols].fillna(train[num_cols].median())
train[cat_cols] = train[cat_cols].fillna("unknown")


print("\n===== IQR Outlier Counts =====")

outlier_indices = set()

for col in num_cols:
    Q1 = train[col].quantile(0.25)
    Q3 = train[col].quantile(0.75)
    IQR = Q3 - Q1

    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    mask = (train[col] < lower) | (train[col] > upper)
    count = mask.sum()

    print(f"{col}: {count}")

    outlier_indices.update(train[mask].index)


print("\nTotal unique anomaly rows:", len(outlier_indices))

anomaly_df = train.loc[list(outlier_indices)]
print("\nSample anomalies:")
print(anomaly_df.head())



for col in num_cols[:4]:   # only first few for speed
    plt.figure()
    sns.boxplot(x=train[col])
    plt.title(f"Boxplot - {col}")
    plt.show()


plt.figure(figsize=(8,6))
sns.heatmap(train[num_cols].corr(), annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()


iso = IsolationForest(contamination=0.05, random_state=42)

train["anomaly_flag"] = iso.fit_predict(train[num_cols])

# -1 = anomaly, 1 = normal
ml_anomalies = train[train["anomaly_flag"] == -1]

print("\nIsolation Forest detected anomalies:", len(ml_anomalies))


clean_train = train[train["anomaly_flag"] != -1]
clean_train.to_csv("train_cleaned.csv", index=False)

print("\nCleaned dataset saved as train_cleaned.csv")

from sklearn.model_selection import train_test_split
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv("train.csv")

print("Shape:", df.shape)

drop_cols = ["Name", "Ticket", "Cabin"]

print(df.head())
print(df.info())

num_cols = df.select_dtypes(include=np.number).columns
cat_cols = df.select_dtypes(exclude=np.number).columns

df[num_cols] = df[num_cols].fillna(df[num_cols].median())

for col in drop_cols:
    if col in df.columns:
        df = df.drop(col, axis=1)
        df.fillna(df.median(numeric_only=True), inplace=True)


for col in df.select_dtypes(include="object").columns:
    df[col] = LabelEncoder().fit_transform(df[col])


model = IsolationForest(contamination=0.05, random_state=42)

df["anomaly_flag"] = model.fit_predict(df)

anomalies = df[df["anomaly_flag"] == -1]

print("Anomalies found:", len(anomalies))

anomalies.to_csv("suspicious_rows.csv", index=False)